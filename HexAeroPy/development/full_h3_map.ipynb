{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad61c3bc-db37-4439-b9e5-adb14bb11b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/sklearn/utils/__init__.py:16: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.22.0)\n",
      "  from scipy.sparse import issparse\n",
      "Setting spark.hadoop.yarn.resourcemanager.principal to quinten.goens\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://spark-vlmvc4wt6y8dxvsr.cml-dev.az-dev.x9er-zkvz.cloudera.site\">https://spark-vlmvc4wt6y8dxvsr.cml-dev.az-dev.x9er-zkvz.cloudera.site</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.types import DoubleType, ArrayType, StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,from_unixtime, min, max, to_date, pandas_udf, col, PandasUDFType, lit, round, array_except\n",
    "from pyspark.sql.types import DoubleType, ArrayType, StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "import os, time\n",
    "import subprocess\n",
    "import os,shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import requests\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "from functools import partial\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import transform\n",
    "from pyproj import Proj, Transformer\n",
    "import pandas as pd\n",
    "import folium\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import shapely.geometry\n",
    "import h3\n",
    "import h3_pyspark\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Settings\n",
    "project = \"project_aiu\"\n",
    "\n",
    "\n",
    "# Getting today's date\n",
    "today = datetime.today().strftime('%d %B %Y')\n",
    "\n",
    "# Spark Session Initialization\n",
    "#shutil.copy(\"/runtime-addons/cmladdon-2.0.40-b150/log4j.properties\", \"/etc/spark/conf/\") # Setting logging properties\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"OSN ADEP ADES Identification\") \\\n",
    "    .config(\"spark.log.level\", \"ERROR\")\\\n",
    "    .config(\"spark.hadoop.fs.azure.ext.cab.required.group\", \"eur-app-aiu-dev\") \\\n",
    "    .config(\"spark.kerberos.access.hadoopFileSystems\", \"abfs://storage-fs@cdpdldev0.dfs.core.windows.net/data/project/aiu.db/unmanaged\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"8G\") \\\n",
    "    .config(\"spark.executor.memory\", \"10G\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"6\") \\\n",
    "    .config(\"spark.network.timeout\", \"800s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"400s\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Get environment variables\n",
    "engine_id = os.getenv('CDSW_ENGINE_ID')\n",
    "domain = os.getenv('CDSW_DOMAIN')\n",
    "\n",
    "# Format the URL\n",
    "url = f\"https://spark-{engine_id}.{domain}\"\n",
    "\n",
    "# Display the clickable URL\n",
    "display(HTML(f'<a href=\"{url}\">{url}</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d81be3-3a83-4f06-827c-3ccc3716bee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = 26ee71ba-7339-4e81-9016-534210eb08f2\n"
     ]
    }
   ],
   "source": [
    "list_of_airports = [\n",
    "    # Top 30 Y2D 2024 (25 July 2024) - As from https://ansperformance.eu/traffic/\n",
    "    'LTFM', 'EHAM', 'EGLL', 'LFPG', 'EDDF', 'LEMD', 'EDDM', 'LIRF', 'EGKK',\n",
    "    'LSZH', 'LGAV', 'EIDW', 'LOWW', 'EKCH', 'LEPA', 'LTFJ', 'LPPT', 'ENGM',\n",
    "    'LIMC', 'LFPO', 'LTAI', 'EGSS', 'ESSA', 'EBBR', 'EGCC', 'EDDB', 'LSGG',\n",
    "    'EPWA', 'LEMG',\n",
    "\n",
    "    # BRA - EUR airports\n",
    "    'SBBR', 'SBGR', 'SBSP', 'SBKP', 'SBRJ', 'SBGL', 'SBCF', 'SBSV', 'SBPA', 'SBCT',\n",
    "\n",
    "    # USA - EUR airports\n",
    "    \"KSLC\", \"KATL\", \"KDTW\", \"KIAH\", \"KCLT\", \"KMSP\", \"KSEA\", \"KSFO\", \"KORD\", \"KLAX\",\n",
    "    \"KPDX\", \"KPHL\", \"KIAD\", \"KPHX\", \"KDFW\", \"KDEN\", \"KSAN\", \"KHOU\", \"KBNA\", \"KSTL\",\n",
    "    \"KBWI\", \"KDCA\", \"KMIA\", \"KMDW\", \"KMEM\", \"KDAL\", \"KBOS\", \"KLGA\", \"KLAS\", \"KTPA\",\n",
    "    \"KJFK\", \"KFLL\", \"KEWR\", \"KMCO\",\n",
    "\n",
    "    \"LEMD\", \"EFHK\", \"ENGM\", \"LIRF\", \"LFPO\", \"EKCH\", \"LEBL\", \"EDDM\", \"LSGG\", \"ESSA\",\n",
    "    \"LOWW\", \"EHAM\", \"EGLL\", \"LSZH\", \"EDDL\", \"LFPG\", \"EDDH\", \"EBBR\", \"EPWA\", \"EDDF\",\n",
    "    \"LGAV\", \"LEMG\", \"LIMC\", \"LFMN\", \"LEPA\", \"EDDB\", \"LROP\", \"EGGW\", \"EGSS\", \"EDDK\",\n",
    "    \"LPPT\", \"LTFM\", \"EIDW\", \"EGKK\",\n",
    "\n",
    "    # CHN - EUR report\n",
    "    \"ZBAA\", \"ZSPD\", \"ZGGG\", \"ZGSZ\", \"ZUUU\", \"ZPPP\", \"ZLXY\", \"ZUCK\", \"ZSHC\", \"ZSSS\",\n",
    "    \"ZYCC\", \"ZSNJ\", \"LTFM\", \"EDDF\", \"EHAM\", \"LFPG\", \"EGLL\", \"LEMD\", \"EDDM\", \"LEBL\",\n",
    "    \"LIRF\", \"EGKK\", \"LSZH\", \"EFHK\",\n",
    "\n",
    "    # PBWG\n",
    "    \"WSSS\", \"VTBS\", \"RJAA\", \"RJTT\", \"SBGR\", \"SBBR\"\n",
    "]\n",
    "\n",
    "# Remove duplicates by converting to a set\n",
    "unique_airports = set(list_of_airports)\n",
    "\n",
    "# Format the list for the SQL IN clause\n",
    "formatted_airports = \", \".join(f\"'{airport}'\" for airport in unique_airports)\n",
    "formatted_airports = f\"({formatted_airports})\"\n",
    "\n",
    "airports_df = spark.sql(f\"\"\"\n",
    "    SELECT id, ident, iso_country, continent, latitude_deg, longitude_deg, elevation_ft, type\n",
    "    FROM {project}.oa_airports\n",
    "    WHERE (type = 'large_airport' OR type = 'medium_airport') AND \n",
    "    ident IN {formatted_airports}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "def generate_circle_polygon(lon, lat, radius_nautical_miles, num_points=360):\n",
    "    \"\"\"\n",
    "    Generate a polygon in GeoJSON format around a given latitude and longitude\n",
    "    with a specified radius in nautical miles.\n",
    "    \n",
    "    :param lat: Latitude of the center point\n",
    "    :param lon: Longitude of the center point\n",
    "    :param radius_nautical_miles: Radius in nautical miles\n",
    "    :param num_points: Number of points to generate for the polygon\n",
    "    :return: A dictionary representing the polygon in GeoJSON format\n",
    "    \"\"\"\n",
    "    # Convert radius from nautical miles to kilometers\n",
    "    radius_km = radius_nautical_miles * 1.852\n",
    "    \n",
    "    # Function to convert from degrees to radians\n",
    "    def degrees_to_radians(degrees):\n",
    "        return degrees * math.pi / 180\n",
    "    \n",
    "    # Function to calculate the next point given a distance and bearing\n",
    "    def calculate_point(lon, lat, distance_km, bearing):\n",
    "        R = 6371.01  # Earth's radius in kilometers\n",
    "        lat_rad = degrees_to_radians(lat)\n",
    "        lon_rad = degrees_to_radians(lon)\n",
    "        distance_rad = distance_km / R\n",
    "        bearing_rad = degrees_to_radians(bearing)\n",
    "        \n",
    "        lat_new_rad = math.asin(math.sin(lat_rad) * math.cos(distance_rad) +\n",
    "                                math.cos(lat_rad) * math.sin(distance_rad) * math.cos(bearing_rad))\n",
    "        lon_new_rad = lon_rad + math.atan2(math.sin(bearing_rad) * math.sin(distance_rad) * math.cos(lat_rad),\n",
    "                                           math.cos(distance_rad) - math.sin(lat_rad) * math.sin(lat_new_rad))\n",
    "                                           \n",
    "        lat_new = math.degrees(lat_new_rad)\n",
    "        lon_new = math.degrees(lon_new_rad)\n",
    "        return [lon_new, lat_new]\n",
    "    \n",
    "    # Generate points\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        bearing = 360 / num_points * i\n",
    "        point = calculate_point(lon, lat, radius_km, bearing)\n",
    "        points.append(point)\n",
    "    points.append(points[0])  # Close the polygon by repeating the first point\n",
    "    \n",
    "    # Create GeoJSON\n",
    "    geojson = {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [points]\n",
    "    }\n",
    "    \n",
    "    geojson_str = json.dumps(geojson)\n",
    "    \n",
    "    return geojson_str\n",
    "\n",
    "def fill_polygon_with_hexagons(polygon_json, resolution=8):\n",
    "    \"\"\"Fills a polygon defined by the given JSON with hexagons with defined resolution.\n",
    "\n",
    "    Args:\n",
    "        polygon_json (str): A JSON string defining the polygon.\n",
    "        resolution (int): The H3 resolution for the hexagons.\n",
    "\n",
    "    Returns:\n",
    "        list: The list contains the compact hexagon IDs.\n",
    "    \"\"\"\n",
    "    polygon = json.loads(polygon_json)\n",
    "    hexagons = h3.polyfill(polygon, resolution, geo_json_conformant=True)\n",
    "    return hexagons\n",
    "\n",
    "def fill_polygon_with_compact_hexagons(polygon_json, resolution=8):\n",
    "    \"\"\"Fills a polygon defined by the given JSON with compact hexagons.\n",
    "\n",
    "    Args:\n",
    "        polygon_json (str): A JSON string defining the polygon.\n",
    "        resolution (int): The H3 resolution for the hexagons.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists. The first list contains the compact hexagon IDs,\n",
    "               and the second list contains the resolutions of these hexagons.\n",
    "    \"\"\"\n",
    "    hexagons = fill_polygon_with_hexagons(polygon_json, resolution)\n",
    "    compact_hexagons = list(h3.compact(hexagons))\n",
    "    compact_hexagons_resolutions = [h3.h3_get_resolution(h) for h in compact_hexagons]\n",
    "    return compact_hexagons, compact_hexagons_resolutions\n",
    "\n",
    "generate_circle_polygon_udf = udf(generate_circle_polygon, StringType())\n",
    "\n",
    "compact_hex_result_type = StructType([\n",
    "    StructField(\"compact_hexagons\", ArrayType(StringType()), False),\n",
    "    StructField(\"compact_hexagons_resolutions\", ArrayType(IntegerType()), False)\n",
    "])\n",
    "\n",
    "fill_polygon_with_compact_hexagons_udf = udf(fill_polygon_with_compact_hexagons, compact_hex_result_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f40172-a074-4bfa-a77e-9765bb734d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:==============>                                            (1 + 1) / 4]\r"
     ]
    }
   ],
   "source": [
    "for max_resolution in [8]:\n",
    "    num_points = 720\n",
    "    radia_nm = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    area_type = [ f\"C{x+10}\" for x in radia_nm]\n",
    "\n",
    "    df = pd.DataFrame.from_dict({ #c stands for circle\n",
    "        'max_resolution' : max_resolution,\n",
    "        'number_of_points_c' : num_points, \n",
    "        'area_type' : area_type,\n",
    "        'min_c_radius_nm' : radia_nm\n",
    "    })\n",
    "\n",
    "    df['max_c_radius_nm'] = df['min_c_radius_nm'].shift(-1).fillna(np.max(radia_nm)+10)\n",
    "    df['min_c_radius_nm'] = df['min_c_radius_nm'].astype(float)\n",
    "    df['max_c_radius_nm'] = df['max_c_radius_nm'].astype(float)\n",
    "    df['m_col'] = 1\n",
    "\n",
    "    # Define the schema corresponding to your Pandas DataFrame structure\n",
    "    schema = StructType([\n",
    "        StructField(\"max_resolution\", IntegerType(), True),\n",
    "        StructField(\"number_of_points_c\", IntegerType(), True),\n",
    "        StructField(\"area_type\", StringType(), True),\n",
    "        StructField(\"min_c_radius_nm\", FloatType(), True),\n",
    "        StructField(\"max_c_radius_nm\", FloatType(), True),\n",
    "        StructField(\"m_col\", IntegerType(), True)\n",
    "    ])\n",
    "\n",
    "    # Create PySpark DataFrame from Pandas DataFrame using the defined schema\n",
    "    sdf = spark.createDataFrame(df, schema=schema)\n",
    "    airports_df_m = airports_df.withColumn('m_col', lit(1)).join(sdf, on = 'm_col', how = 'left')\n",
    "\n",
    "    res = airports_df_m.withColumn(\n",
    "        \"inner_circle_polygon\",\n",
    "        generate_circle_polygon_udf(\n",
    "            F.col('longitude_deg'),\n",
    "            F.col('latitude_deg'),\n",
    "            F.col('min_c_radius_nm'), \n",
    "            F.col('number_of_points_c')\n",
    "        )).withColumn(\n",
    "        \"outer_circle_polygon\",\n",
    "        generate_circle_polygon_udf(\n",
    "            F.col('longitude_deg'),\n",
    "            F.col('latitude_deg'),\n",
    "            F.col('max_c_radius_nm'), \n",
    "            F.col('number_of_points_c')\n",
    "        )).withColumn(\n",
    "            \"inner_circle_hex_ids\",\n",
    "            h3_pyspark.polyfill(\n",
    "                F.col(\"inner_circle_polygon\"),\n",
    "                F.col(\"max_resolution\"),\n",
    "                F.lit(True)\n",
    "        )).withColumn(\n",
    "            \"outer_circle_hex_ids\",\n",
    "            h3_pyspark.polyfill(\n",
    "                F.col(\"outer_circle_polygon\"),\n",
    "                F.col(\"max_resolution\"),\n",
    "                F.lit(True)\n",
    "        )).withColumn(\n",
    "            \"hex_id\",\n",
    "            array_except(col(\"outer_circle_hex_ids\"), col(\"inner_circle_hex_ids\"))\n",
    "        ).drop(\n",
    "            \"inner_circle_polygon\", \n",
    "            \"outer_circle_polygon\", \n",
    "            \"inner_circle_hex_ids\", \n",
    "            \"outer_circle_hex_ids\").toPandas()\n",
    "\n",
    "    #res = res.drop([\"inner_circle_polygon\", \"outer_circle_polygon\", \"inner_circle_hex_ids\", \"outer_circle_hex_ids\"], axis=1)\n",
    "    res.to_parquet(f'../../data/airport_hex/airport_concentric_c_hex_res_{max_resolution}_RQ_request.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43a8784-d8ad-440f-9dcc-d75620987d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import h3\n",
    "\n",
    "def hexagons_dataframe_to_geojson(df_hex, file_output=None):\n",
    "    \"\"\"\n",
    "    Produce the GeoJSON for a dataframe, constructing the geometry from the \"hex_id\" column\n",
    "    and including all other columns as properties.\n",
    "    \"\"\"\n",
    "    list_features = []\n",
    "\n",
    "    for i, row in df_hex.iterrows():\n",
    "        try:\n",
    "            geometry_for_row = {\"type\": \"Polygon\", \"coordinates\": [h3.h3_to_geo_boundary(h=row[\"hex_id\"], geo_json=True)]}\n",
    "            properties = row.to_dict()  # Convert all columns to a dictionary\n",
    "            properties.pop(\"hex_id\", None)  # Remove hex_id as it's already used in geometry\n",
    "            feature = Feature(geometry=geometry_for_row, id=row[\"hex_id\"], properties=properties)\n",
    "            list_features.append(feature)\n",
    "        except Exception as e:\n",
    "            print(f\"An exception occurred for hex {row['hex_id']}: {e}\")\n",
    "\n",
    "    feat_collection = FeatureCollection(list_features)\n",
    "    geojson_result = json.dumps(feat_collection)\n",
    "    return geojson_result\n",
    "\n",
    "\n",
    "def get_color(custom_cm, val, vmin, vmax):\n",
    "    return matplotlib.colors.to_hex(custom_cm((val-vmin)/(vmax-vmin)))\n",
    "\n",
    "def choropleth_map(df_aggreg, column_name=\"value\", border_color='black', fill_opacity=0.7, color_map_name=\"Blues\", initial_map=None, initial_location=[47, 4], initial_zoom=5.5, tooltip_columns=None):\n",
    "    \"\"\"\n",
    "    Creates choropleth maps given the aggregated data. \n",
    "    initial_map can be an existing map to draw on top of.\n",
    "    initial_location and initial_zoom control the initial view of the map.\n",
    "    tooltip_columns is a list of column names to display in a tooltip.\n",
    "    \"\"\"\n",
    "    # colormap\n",
    "    min_value = df_aggreg[column_name].min()\n",
    "    max_value = df_aggreg[column_name].max()\n",
    "    mean_value = df_aggreg[column_name].mean()\n",
    "    print(f\"Colour column min value {min_value}, max value {max_value}, mean value {mean_value}\")\n",
    "    print(f\"Hexagon cell count: {df_aggreg['hex_id'].nunique()}\")\n",
    "\n",
    "    # Create map if not provided\n",
    "    if initial_map is None:\n",
    "        initial_map = folium.Map(location=initial_location, zoom_start=initial_zoom, tiles=\"cartodbpositron\")\n",
    "\n",
    "    # Create geojson data from dataframe\n",
    "    geojson_data = hexagons_dataframe_to_geojson(df_hex=df_aggreg)\n",
    "\n",
    "    # Get colormap\n",
    "    custom_cm = matplotlib.cm.get_cmap(color_map_name)\n",
    "\n",
    "    # Add GeoJson to map\n",
    "    folium.GeoJson(\n",
    "        geojson_data,\n",
    "        style_function=lambda feature: {\n",
    "            'fillColor': get_color(custom_cm, feature['properties'][column_name], vmin=min_value, vmax=max_value),\n",
    "            'color': border_color,\n",
    "            'weight': 1,\n",
    "            'fillOpacity': fill_opacity\n",
    "        },\n",
    "        tooltip=folium.features.GeoJsonTooltip(fields=tooltip_columns) if tooltip_columns else None,\n",
    "        name=\"Choropleth\"\n",
    "    ).add_to(initial_map)\n",
    "\n",
    "    return initial_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a110ff85-6479-400e-8d45-d6f3686d9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res = pd.read_parquet(f'../../data/airport_hex/airport_concentric_c_hex_res_7_RQ_request.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505d4ce4-4491-4ded-ab09-01f66739dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.explode(\"hex_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63060595-47b8-4c8c-8f9d-9bb6ddbdd02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colour column min value 10.0, max value 110.0, mean value 78.20936584472656\n",
      "Hexagon cell count: 28152\n"
     ]
    }
   ],
   "source": [
    "fig = choropleth_map(res[res['ident']=='EGLL'], column_name = \"max_c_radius_nm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b3b550-4fce-44d7-8b09-862c0ae8f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.save('example_EGLL_for_RQ.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
